- al ensayo me gustaria agregar(el libro nexus de yuval noah harari), la importacia de como los algoritmos(actores no humanos, que entraron hace poco al campo geopolitico como un ente casi autonomo con, con una supuesta correa en su cuello controlada por una bigtech, que escondio sus estudios de como su red social afecta negativamente a la vida y psique de las personas), como han ocurrido genociodios porque un algoritmo confidio el contexto y la falta de actores humanos moderando dio paso a que por primera vez un actor no humano afectara su historia tan profundamente, el algoritmo no se entienda de forma atropomorfica, no tiene una naturaleza como tal, ni malicia, ni pensamientos, solo entiende la fria logica informatica, es un espejo humano por esto tiene sesgos, idiologia, un actor neutral es imposible
	- Se dice que el pueblo *rohingya* (o *rohinya*) es el 
	  más perseguido del mundo. A pesar de que su historia está vinculada 
	  desde hace siglos al estado de Rakhine, en el oeste de lo que hoy es 
	  Myanmar, las personas *rohingya* no tienen patria. Tras años de 
	  discriminaciones y violencias, en agosto de 2017, el ejército de Myanmar
	   lanzó una ofensiva contra comunidades *rohingyas* que, [según estimaciones de la ONU](https://news.un.org/es/story/2023/08/1523592),
	   asesinó a unas diez mil personas y expulsó a más de 700 mil. La mayoría
	   siguen en campos de personas refugiadas, especialmente en [Cox’s Bazar](https://www.acnur.org/emergencias/emergencia-rohingya), en Bangladesh.
	  
	  Aquel episodio marcó un punto de inflexión por la brutalidad de la limpieza étnica y, también, por **el papel que jugaron las redes sociales**
	   –en especial Facebook– en la escalada del odio y la desinformación que 
	  precedieron a la masacre. Desde entonces, el conflicto no ha cesado. En 
	  febrero de 2021, el ejército dio un golpe de Estado y tomó el control 
	  del país. En 2024, la población rohingya sufrió los peores episodios de 
	  violencia desde 2017 según el [informe anual de Amnistía Internacional](https://www.amnesty.org/es/documents/pol10/7200/2024/es/)
	   sobre la situación de los derechos humanos en el mundo. También la 
	  Oficina del Alto Comisionado de las Naciones Unidas para los Derechos 
	  Humanos [declaró a principios de año](https://www.ohchr.org/es/press-releases/2025/01/myanmar-four-years-coup-leaders-ramp-violations-unprecedented-levels-un)
	   que el ejército de Myanmar incrementó la violencia contra la población 
	  civil durante 2024 y causó el mayor número de muertes de civiles desde 
	  el golpe de Estado. En los últimos cuatro años, se estima que al menos 
	  han muerto 6.231 civiles, según [los datos de AAPP](https://aappb.org/?p=31836).
	  
	  > 
	  
	  Según
	   Amnistía Internacional, Meta fue consciente de los riesgos asociados a 
	  sus algoritmos, pero no tomó medidas adecuadas para mitigarlos
	  
	  ¿Cuál fue el origen de todas estas violencias? La [historia de Myanmar](https://www.unav.edu/web/global-affairs/detalle/-/blogs/rohingyas-el-porque-de-un-conflicto)
	   está marcada por una compleja mezcla de etnias, religiones y conflictos
	   territoriales. Durante la Segunda Guerra Mundial, el Imperio británico 
	  armó al pueblo *rohingya*, de religión musulmana, para resistir 
	  la invasión japonesa. El uso de esa fuerza armada generó tensiones con 
	  otras comunidades, sobre todo budistas. Tras la independencia en 1948, y
	   en un contexto de multiplicación de grupos insurgentes, la comunidad *rohingya*
	   fue identificada por el Estado como una amenaza potencial, 
	  especialmente a raíz de la creación de partidos armados. En 1982, la 
	  exclusión de las personas *rohingya* se formalizó con la Ley de 
	  Ciudadanía, que les negó el reconocimiento como uno de los grupos 
	  étnicos nacionales, privándoles de derechos básicos al ser consideradas 
	  inmigrantes ilegales. **A pesar de que esta ley vulnera el derecho internacional, aún sigue vigente.**
	  
	  Tras
	   décadas bajo una dictadura militar, el país inició en 2010 un proceso 
	  de apertura política, pero con muchas limitaciones. La violencia 
	  continuó y las tensiones crecientes desembocaron en 2017 en una masacre 
	  que organizaciones internacionales han calificado de genocidio.
	- ## Cuando el algoritmo amplifica el odio
	  
	  Pero ¿qué papel jugó Facebook en 2017? Según [un informe elaborado por Amnistía Internacional en 2022](https://www.amnesty.org/es/latest/news/2022/09/myanmar-facebooks-systems-promoted-violence-against-rohingya-meta-owes-reparations-new-report/),
	  Facebook se convirtió en una «cámara de resonancia de contenido 
	  virulento antirrohingya» en Myanmar antes y durante la escalada de 
	  violencia. Grupos vinculados al ejército y radicales nacionalistas 
	  budistas llenaron la plataforma de **publicaciones cargadas de odio**
	  que incitaban a la violencia y anunciaban una inminente toma del poder 
	  musulmana en el país. ¿Qué hizo Facebook para frenar estas 
	  desinformaciones? Ignoró las quejas de quienes alertaban de estos 
	  mensajes que incitaban a la violencia y a la discriminación en medio de 
	  un conflicto. Los algoritmos hicieron el resto.
	  
	  De hecho, el 
	  informe revela que Meta (antes Facebook) fue consciente durante años de 
	  los riesgos asociados a sus algoritmos, pero no tomó medidas adecuadas 
	  para mitigarlos. Por ejemplo, en 2014, Meta intentó apoyar una 
	  iniciativa contra el odio conocida como «Panzagar» (o *discurso de la flor*). Se trataba de un paquete de *stickers*
	  que contenían mensajes como «Piensa antes de compartir» o «No seas la 
	  causa de la violencia» y que eran utilizados para responder a los 
	  contenidos que hicieran apología de la violencia o la discriminación. 
	  Sin embargo, como explica Amnistía Internacional, el algoritmo de la 
	  plataforma interpretó el uso de estas pegatinas como una señal de 
	  popularidad y aumentó la visibilidad de los posts que buscaban combatir,
	  lo que tuvo un efecto contrario al esperado.
	  
	  Este informe también
	  señala que estudios internos, que datan incluso de 2012, ya advertían 
	  de que los sistemas que determinan qué contenido mostrar podían causar 
	  daños graves fuera de Internet. En 2016, una investigación interna 
	  reconoció explícitamente que **los sistemas de recomendación de Facebook aumentan el problema del extremismo**.
	  Sin embargo, Meta decidió no actuar, dejando que estos algoritmos 
	  siguieran amplificando contenidos que ponen en riesgo los derechos 
	  humanos.
	  
	  Además, Amnistía Internacional denunció que los [Papeles de Facebook](https://ethic.es/2022/03/facebook-files-y-el-espejismo-de-la-privacidad/) exponen con detalle cómo, en lugar de priorizar la seguridad y el bienestar social, **Meta continuó ignorando estos problemas**
	  porque los contenidos virales implican más gente en sus redes. De 
	  hecho, este informe alude a un documento interno de agosto de 2019, en 
	  el que la empresa reconoce que el discurso de odio, la polarización 
	  política y la desinformación crecen en sus plataformas como consecuencia
	  de las propias mecánicas de viralidad, recomendaciones y optimización 
	  para la participación. Esta combinación convierte a Meta en un actor 
	  central en la difusión de los mensajes.
	  
	  La pasividad de Facebook 
	  también se demuestra en los pocos recursos destinados a moderar 
	  contenidos en algunos países. En 2014, la empresa reconoció que solo 
	  tenía una persona de habla birmana encargada de revisar contenido 
	  relacionado con Myanmar, y trabajaba desde Dublín.
	- ## Meta no puede mirar para otro lado
	  
	  Frente
	  a esta evidencia, el informe no solo denuncia la inacción de Meta, sino
	  que reclama medidas concretas de reparación. Entre otras cosas, este 
	  informe pidió trabajar con las personas sobrevivientes y las 
	  organizaciones de la sociedad civil para calcular y proporcionar una 
	  indemnización adecuada. Esta reparación debería cubrir los daños físicos
	  y psíquicos, las oportunidades perdidas (de empleo, educación y 
	  prestaciones sociales), los daños materiales y la pérdida de ingresos. 
	  Además, se solicita a Meta que proporcione atención jurídica, médica y 
	  psicológica, **que reconozca públicamente el alcance de su contribución a los daños** en derechos humanos, pida disculpas directamente a las víctimas y se comprometa a revisar su modelo de negocio.
	  
	  > 
	  
	  Meta no ha ofrecido reparación a las víctimas ni ha aumentado los recursos de moderación
	  
	  Lejos
	  de asumir responsabilidades, Meta no ha ofrecido una reparación 
	  adecuada a las víctimas y, además, ha reducido recursos en moderación y 
	  automatización de controles, lo que organizaciones advierten relaja las 
	  restricciones al discurso de odio. Amnistía Internacional ha insistido 
	  en que esta decisión [podría tener un impacto en el conflicto de Myanmar](https://www.amnistia.org/en/news/2025/02/28156/meta-s-new-content-policies-risk-fueling-more-mass-violence-and-genocide), como ya ocurrió en 2017.
	  
	  Ahora, Meta tendrá que enfrentarse a la denuncia que, con el respaldo de Amnistía y otras organizaciones, ha realizado [Maung Sawyeddollah](https://www.amnesty.org/es/latest/news/2025/01/united-states-rohingya-survivor-asks-us-regulator-to-investigate-metas-potential-role-in-myanmar-atrocities/), activista *rohingya*
	  y superviviente de la violencia en Myanmar, frente a la Comisión de 
	  Valores y Bolsa de Estados Unidos (SEC, por sus siglas en inglés). Esta 
	  denuncia no se centra en violaciones de derechos humanos directamente, 
	  sino en algo muy concreto: acusa a Meta de haber engañado a sus 
	  accionistas.
	  
	  Según la denuncia, Meta ocultó o minimizó su papel en
	  la difusión del discurso de odio contra los rohingya y su contribución 
	  al genocidio de 2017, incumpliendo sus propias normas comunitarias. Al 
	  no informar a inversores y al SEC sobre estos riesgos, la empresa podría
	  haber violado las leyes federales que exigen transparencia. La 
	  documentación sostiene que la empresa fue advertida en repetidas 
	  ocasiones por activistas y organizaciones sobre el uso de Facebook para 
	  incitar a la violencia en Myanmar. Sin embargo, Meta no incluyó esta 
	  información en sus comunicaciones oficiales con inversores, omitiendo un
	  riesgo material con graves implicaciones para los derechos humanos. 
	  Mientras tanto, las víctimas *rohingyas* siguen esperando justicia, reparación y que quienes permitieron la amplificación del odio asuman
- tambien me gustaria agregar un apartado como una guia 7.1 opsec y soberania digital que se puede extrapolar sobre la privacidad, que la guia sea algo mas extensa (usar navegadores seguros, encriptacion, rrss con cifrado, revisar en que pais las leyes protegen la privacidad donde estan los servidores, contraseñas seguras, claves privadas, conocer con quien estamos hablando, metodologias de hacking etico para entender los ataques, etc), ya sea en internet y fuera, es preciso que agencias o estados de naturaleza cambiante dependiendo de los tiempos, se nos pueda jusgar en el futuro por extremismo, radicalismo, terrorismo y todos los ismos para defender su narrativa artifical, no sabes si en el maña tu democracia se vuelva una dictadura, si un pais te ataca usando metodos nuevos como propaganda dirigida por algoritmos, ciberguerra, guerra psicologia a travez de redes sociales, criptofacismo, autismo armado, etc
- Las IA pueden ser una buena herramienta, pero diferenciar entre lo que es una IAG y un modelo de lenguaje, de imagenes, etc, la ia tiene sesgos, ideologia, comete errores, etc. Tiene todos los defectos del humano, se censura y miente(otra vez no por malicia pura, si no por una variedad de razones, desde la matematica, probabilidad hasta la mas tecnica o como yo creo que al ser entrenado con informacion indiscriminada de todas las ramas de pensamiento se genera una serie de contradicciones ya que toda verdad es medio falsa, creer que la ia llegue a la IAG o un estado de neutralidad u sea un ser inteligente superior moral y eticamente al humano es caer de nuevo en la creencia de la verdad, si se genera un ser artificial va tener sus propios problemas, heredados de nosotros)
- pag 16, Miller, modificar, el mundo nos llama por trabajo y nosotros respondemos....